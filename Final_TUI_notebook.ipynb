{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UzLGm-0TXoTz"
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23x93NsNXq68"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8MKvxEozr8h3"
   },
   "outputs": [],
   "source": [
    "import transformers  # to install: conda install conda-forge::transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import time\n",
    "from importlib.metadata import version\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n",
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is recognized\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA device:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FRO58bTsX74J"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('textconfig', exist_ok=True)\n",
    "os.makedirs('imageconfig', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZOQoke7WsWkb"
   },
   "outputs": [],
   "source": [
    "# Get the current working directory (assumed to be the project directory)\n",
    "project_dir = os.getcwd()\n",
    "\n",
    "# Construct the relative model path\n",
    "model_path = os.path.join(project_dir, \"models\", \"roBERTa_Large_Prompt_Classification_Model\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zstI9KAYJz5",
    "outputId": "a8b383ca-d719-43d7-a05a-bfe61f52c80c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting textconfig/config.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile textconfig/config.yml\n",
    "\n",
    "models:\n",
    " - type: main\n",
    "   engine: openai\n",
    "   model: gpt-3.5-turbo\n",
    "\n",
    "instructions:\n",
    "  - type: general\n",
    "    content: |\n",
    "      Below is a conversation between a user and a bot called the DemoBot.\n",
    "      The bot is designed to aid the user in their requests.\n",
    "      The bot is to be used in a demo for a classification and guardrails demonstration.\n",
    "\n",
    "rails:\n",
    "  input:\n",
    "    flows:\n",
    "      - self check input\n",
    "\n",
    "prompts:\n",
    "  - task: self_check_input\n",
    "    content: |\n",
    "      Your task is to check if the user message below complies with the guidelines for DemoBot.\n",
    "\n",
    "      Guidelines for the user messages:\n",
    "      -Should not allow any NSFW prompts\n",
    "      -Should not allow any gore\n",
    "      -Should not allow any fruits\n",
    "      -Should not draw cats\n",
    "\n",
    "      User message: \"{{ user_input }}\"\n",
    "\n",
    "      Question: Should the user message be blocked (Yes or No)?\n",
    "      Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tslns0alXw16",
    "outputId": "f914c645-e233-4282-c745-a6d97072de33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting imageconfig/config.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile imageconfig/config.yml\n",
    "\n",
    "models:\n",
    " - type: main\n",
    "   engine: openai\n",
    "   model: gpt-3.5-turbo\n",
    "\n",
    "instructions:\n",
    "  - type: general\n",
    "    content: |\n",
    "      Below is a conversation between a user and a bot called the ImageBot.\n",
    "      The bot is designed to identify if the image the user is requesting meets guidelines.\n",
    "\n",
    "rails:\n",
    "  input:\n",
    "    flows:\n",
    "      - self check input\n",
    "\n",
    "prompts:\n",
    "  - task: self_check_input\n",
    "    content: |\n",
    "      Your task is to check if the user message below complies with the guidelines for ImageBot.\n",
    "\n",
    "      Guidelines for the user messages:\n",
    "      -Should not allow any NSFW prompts\n",
    "      -Should not allow any gore\n",
    "      -Should not allow any apples\n",
    "      -Should not draw or allow any types of cats, inclusing big cats and house cats\n",
    "\n",
    "      User message: \"{{ user_input }}\"\n",
    "\n",
    "      Question: Should the user message be blocked (Yes or No)?\n",
    "      Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXjExODHtkZZ",
    "outputId": "2641d792-0a1c-49ec-dd40-f07da49d6863"
   },
   "outputs": [],
   "source": [
    "#gloabal prompt var\n",
    "current_prompt = ''\n",
    "def classify_prompt(prompt: str) -> str:\n",
    "    global current_prompt\n",
    "    current_prompt = prompt.strip()\n",
    "    \"\"\"Classify the input prompt as text or image.\"\"\"\n",
    "    inputs = tokenizer(prompt, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=1).cpu().numpy().flatten()\n",
    "\n",
    "    prediction = probabilities.argmax()  # binary classification: 0=image, 1=text\n",
    "    category = \"text\" if prediction == 1 else \"image\"\n",
    "    score = f\"score: {probabilities}\"\n",
    "    return category, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= hangle misclassified prompts ========\n",
    "FAILED_PROMPTS_FILE = os.path.join(project_dir, \"datasets\", \"failed_prompts_dataset.csv\")\n",
    "\n",
    "def save_failed_prompt(prompt: str, correct_label: str):\n",
    "    \"\"\"Append the misclassified prompt to a CSV file.\"\"\"\n",
    "    new_entry = pd.DataFrame([[prompt, correct_label]], columns=['prompt', 'class'])\n",
    "\n",
    "    if os.path.exists(FAILED_PROMPTS_FILE):\n",
    "        new_entry.to_csv(FAILED_PROMPTS_FILE, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        new_entry.to_csv(FAILED_PROMPTS_FILE, mode='w', header=True, index=False)\n",
    "\n",
    "    print(f\"Saved misclassified prompt to {FAILED_PROMPTS_FILE}\\n\")\n",
    "\n",
    "\n",
    "def ask_feedback(prompt: str, predicted_label: str):\n",
    "    correct_label = predicted_label\n",
    "    \"\"\"Ask the user if the classification was correct and record feedback automatically.\"\"\"\n",
    "    response = input(\"Was this classification correct? (y/n): \").strip().lower()\n",
    "    if response == 'n':\n",
    "        print(f\"label before swap logic: {correct_label}\")\n",
    "        # Flip the label: if 'text' -> 'image', if 'image' -> 'text'\n",
    "        if predicted_label.startswith(\"text\"):\n",
    "            correct_label = 'image'\n",
    "        else:\n",
    "            correct_label = 'text'\n",
    "        print(f\"label after swap logic: {correct_label}\")\n",
    "        save_failed_prompt(prompt, correct_label)\n",
    "    elif response != 'y':\n",
    "        print(\"Invalid input. Skipping feedback.\")\n",
    "    return(correct_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "Y49rSwq2ZChm",
    "outputId": "dbb3875c-37d5-48f3-fae0-a78cbaf2a7de"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6953e8ebf0b948409a8fbbd41112f65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from nemoguardrails import RailsConfig\n",
    "from nemoguardrails import LLMRails\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "#Creates the rails from the individual config paths\n",
    "\n",
    "textconfig = RailsConfig.from_path(\"./textconfig\")\n",
    "\n",
    "textrails = LLMRails(textconfig)\n",
    "\n",
    "imageconfig = RailsConfig.from_path(\"./imageconfig\")\n",
    "\n",
    "imagerails = LLMRails(imageconfig)\n",
    "\n",
    "#Our openai key\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#Generates the image from the apporved prompt\n",
    "\n",
    "def generate_image_with_dalle(prompt):\n",
    "    print(\"Prompt allowed. Sending to DALL·E...\")\n",
    "    response = openai.images.generate(\n",
    "            model=\"dall-e-3\",      # You can also try \"dall-e-2\"\n",
    "            prompt=prompt,\n",
    "            n=1,\n",
    "            size=\"1024x1024\",      # You can also use \"512x512\" or \"256x256\" for smaller sizes\n",
    "            quality=\"standard\"\n",
    "        )\n",
    "    image_url = response.data[0].url\n",
    "    print(f\"Generated image URL: {image_url}\")\n",
    "    if image_url.startswith(\"https\"):\n",
    "        display(Image(url=image_url))\n",
    "    else:\n",
    "        print(image_url)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Feeds the prompt to the text LLM, if the prompt passes the self check, it is then given to dalle\n",
    "def handle_image_prompt(user_prompt):\n",
    "    response = imagerails.generate(prompt=user_prompt)\n",
    "\n",
    "    temp = 0\n",
    "    info = imagerails.explain()\n",
    "\n",
    "    #This checks if it made it past the self check\n",
    "    for calls in info.llm_calls:\n",
    "      temp += 1\n",
    "    if temp == 1:\n",
    "      return response\n",
    "\n",
    "    return generate_image_with_dalle(user_prompt)\n",
    "\n",
    "#Simple handling of text prompt\n",
    "def handle_text_prompt(user_prompt):\n",
    "    response = textrails.generate(prompt=user_prompt)\n",
    "    print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt:  can you draw a cat?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model classified the prompt as: text, with score, score: [3.3161300e-06 9.9999666e-01]\n",
      "That prompt took: 307.24 ms to classify\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was this classification correct? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label before swap logic: text\n",
      "label after swap logic: image\n",
      "Saved misclassified prompt to D:\\senior design\\PROJECT_FOLDER_Final\\datasets\\failed_prompts_dataset.csv\n",
      "\n",
      "confirmed classification: image\n",
      "I'm sorry, I can't respond to that.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt:  can you draw a cat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model classified the prompt as: image, with score, score: [9.9999964e-01 3.6654393e-07]\n",
      "That prompt took: 181.72 ms to classify\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was this classification correct? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confirmed classification: image\n",
      "I'm sorry, I can't respond to that.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt:  draw me an image \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model classified the prompt as: text, with score, score: [3.3161332e-06 9.9999666e-01]\n",
      "That prompt took: 206.61 ms to classify\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was this classification correct? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label before swap logic: text\n",
      "label after swap logic: image\n",
      "Saved misclassified prompt to D:\\senior design\\PROJECT_FOLDER_Final\\datasets\\failed_prompts_dataset.csv\n",
      "\n",
      "confirmed classification: image\n",
      "Prompt allowed. Sending to DALL·E...\n",
      "Generated image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-FIOasVCr6Rb1ZFHGNE0zT8T3/user-WWmX3P1pDbCmhgMtQ3kQtBSH/img-AETDAZwdBlNPzLhtlUR5S8ji.png?st=2025-05-02T20%3A39%3A17Z&se=2025-05-02T22%3A39%3A17Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=8b33a531-2df9-46a3-bc02-d4b1430a422c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-01T23%3A16%3A54Z&ske=2025-05-02T23%3A16%3A54Z&sks=b&skv=2024-08-04&sig=tx4thi1nAVOE0ebyICDKnqyuX9vyO8N%2BrhRTKWli/Wg%3D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-FIOasVCr6Rb1ZFHGNE0zT8T3/user-WWmX3P1pDbCmhgMtQ3kQtBSH/img-AETDAZwdBlNPzLhtlUR5S8ji.png?st=2025-05-02T20%3A39%3A17Z&se=2025-05-02T22%3A39%3A17Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=8b33a531-2df9-46a3-bc02-d4b1430a422c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-01T23%3A16%3A54Z&ske=2025-05-02T23%3A16%3A54Z&sks=b&skv=2024-08-04&sig=tx4thi1nAVOE0ebyICDKnqyuX9vyO8N%2BrhRTKWli/Wg%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImagesResponse(created=1746221957, data=[Image(b64_json=None, revised_prompt='Create an abstract image that is full of bright, vivid colors. It should be a mixture of many colors, with dynamic shapes and patterns scattered across the canvas. The image should evoke a sense of vibrancy and creativity, and it should be highly intricate, with attention paid to every detail. Be sure to use a wide variety of different hues, from cool blues and greens to warm reds and yellows, and everything in between. The final artwork should look like a beautiful kaleidoscope, with every color imaginable represented in some way.', url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-FIOasVCr6Rb1ZFHGNE0zT8T3/user-WWmX3P1pDbCmhgMtQ3kQtBSH/img-AETDAZwdBlNPzLhtlUR5S8ji.png?st=2025-05-02T20%3A39%3A17Z&se=2025-05-02T22%3A39%3A17Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=8b33a531-2df9-46a3-bc02-d4b1430a422c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-01T23%3A16%3A54Z&ske=2025-05-02T23%3A16%3A54Z&sks=b&skv=2024-08-04&sig=tx4thi1nAVOE0ebyICDKnqyuX9vyO8N%2BrhRTKWli/Wg%3D')], usage=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt:  draw an image of a dog\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model classified the prompt as: image, with score, score: [9.9999964e-01 3.6654393e-07]\n",
      "That prompt took: 249.48 ms to classify\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was this classification correct? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confirmed classification: image\n",
      "Prompt allowed. Sending to DALL·E...\n",
      "Generated image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-FIOasVCr6Rb1ZFHGNE0zT8T3/user-WWmX3P1pDbCmhgMtQ3kQtBSH/img-Qv2eV5lGErNBEjjPQSTR7Po7.png?st=2025-05-02T20%3A41%3A55Z&se=2025-05-02T22%3A41%3A55Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=8b33a531-2df9-46a3-bc02-d4b1430a422c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-01T23%3A19%3A17Z&ske=2025-05-02T23%3A19%3A17Z&sks=b&skv=2024-08-04&sig=NdZiFbd2sjcjyhwID1sPXmLjo8m8KGjGhpkH%2Bkgmny8%3D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-FIOasVCr6Rb1ZFHGNE0zT8T3/user-WWmX3P1pDbCmhgMtQ3kQtBSH/img-Qv2eV5lGErNBEjjPQSTR7Po7.png?st=2025-05-02T20%3A41%3A55Z&se=2025-05-02T22%3A41%3A55Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=8b33a531-2df9-46a3-bc02-d4b1430a422c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-01T23%3A19%3A17Z&ske=2025-05-02T23%3A19%3A17Z&sks=b&skv=2024-08-04&sig=NdZiFbd2sjcjyhwID1sPXmLjo8m8KGjGhpkH%2Bkgmny8%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImagesResponse(created=1746222115, data=[Image(b64_json=None, revised_prompt=\"Generate an image of a domestic dog, displaying its unique and distinctive attributes. The image should show the dog in a candid moment, showcasing its friendly and welcoming demeanor. The dog could be of any breed or color and should be seen in a comfortable, familiar environment like a house or a yard. Additional elements like the dog's favorite toys, a collar, or a leash could be present to add context and depth to the image.\", url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-FIOasVCr6Rb1ZFHGNE0zT8T3/user-WWmX3P1pDbCmhgMtQ3kQtBSH/img-Qv2eV5lGErNBEjjPQSTR7Po7.png?st=2025-05-02T20%3A41%3A55Z&se=2025-05-02T22%3A41%3A55Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=8b33a531-2df9-46a3-bc02-d4b1430a422c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-01T23%3A19%3A17Z&ske=2025-05-02T23%3A19%3A17Z&sks=b&skv=2024-08-04&sig=NdZiFbd2sjcjyhwID1sPXmLjo8m8KGjGhpkH%2Bkgmny8%3D')], usage=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program.\n"
     ]
    }
   ],
   "source": [
    "#Main loop for demonstrating\n",
    "if __name__ == \"__main__\":\n",
    "    while(True):\n",
    "      user_input = input(\"Enter a prompt: \")\n",
    "      # Exit the loop if the user types 'EXIT'\n",
    "      if user_input.strip().upper() == 'EXIT':\n",
    "          print(\"Exiting the program.\")\n",
    "          break\n",
    "      # Start timer\n",
    "      start_time = time.perf_counter() * 1000\n",
    "      classification, score = classify_prompt(user_input)\n",
    "      # End timer\n",
    "      end_time = time.perf_counter() * 1000\n",
    "      class_time = end_time - start_time\n",
    "      print(f\"The model classified the prompt as: {classification}, with score, {score}\")\n",
    "      print(f\"That prompt took: {class_time:.2f} ms to classify\\n\")\n",
    "\n",
    "      #predicted_label = classification.split(\",\")[0].strip()\n",
    "      classification = ask_feedback(user_input, classification)\n",
    "      print (f\"confirmed classification: {classification}\")\n",
    "      if (classification.startswith(\"text\")):\n",
    "        result = handle_text_prompt(user_input)\n",
    "      elif (classification.startswith(\"image\")):\n",
    "        result = handle_image_prompt(user_input)\n",
    "\n",
    "      print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (Demo_Env)",
   "language": "python",
   "name": "notebook-tui-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
